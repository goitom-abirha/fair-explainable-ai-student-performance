{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "2240b647-c513-42a2-a631-216b7728ed92",
   "metadata": {},
   "source": [
    "# Week 3 — Data Preprocessing & Feature Engineering\r\n",
    "\r\n",
    "This notebook prepares the Portuguese Student Performance dataset for machine learning modeling.  \r\n",
    "It includes:\r\n",
    "- Data cleaning  \r\n",
    "- Handling missing values  \r\n",
    "- Encoding categorical features  \r\n",
    "- Scaling numerical features  \r\n",
    "- Basic feature engineering  \r\n",
    "- Saving a processed dataset for Week 4 model training.\r\n",
    ".\r\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c2d26731-d460-4337-8c31-1eee5bfd5d24",
   "metadata": {},
   "source": [
    "## 1. Import Required Libraries\r\n",
    "\r\n",
    "In this step, we import the main Python libraries needed for preprocessing and transforming the dataset before training machine-learning models.\r\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "67bfed3e-d638-48af-8d87-d233c3512c3d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "from sklearn.preprocessing import OneHotEncoder, StandardScaler\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.pipeline import Pipeline"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b2f13685-ff47-4fc1-8b81-73403ea4f644",
   "metadata": {},
   "source": [
    "## 2. Load the Dataset\r\n",
    "\r\n",
    "We load the Portuguese student performance dataset (`student-por.csv`) from the UCI repository.  \r\n",
    "This raw dataset will be used as the starting point for all preprocessing steps.ng."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "2210d6aa-bafb-432f-bdeb-258abea90f36",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>school</th>\n",
       "      <th>sex</th>\n",
       "      <th>age</th>\n",
       "      <th>address</th>\n",
       "      <th>famsize</th>\n",
       "      <th>Pstatus</th>\n",
       "      <th>Medu</th>\n",
       "      <th>Fedu</th>\n",
       "      <th>Mjob</th>\n",
       "      <th>Fjob</th>\n",
       "      <th>...</th>\n",
       "      <th>famrel</th>\n",
       "      <th>freetime</th>\n",
       "      <th>goout</th>\n",
       "      <th>Dalc</th>\n",
       "      <th>Walc</th>\n",
       "      <th>health</th>\n",
       "      <th>absences</th>\n",
       "      <th>G1</th>\n",
       "      <th>G2</th>\n",
       "      <th>G3</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>GP</td>\n",
       "      <td>F</td>\n",
       "      <td>18</td>\n",
       "      <td>U</td>\n",
       "      <td>GT3</td>\n",
       "      <td>A</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>at_home</td>\n",
       "      <td>teacher</td>\n",
       "      <td>...</td>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>11</td>\n",
       "      <td>11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>GP</td>\n",
       "      <td>F</td>\n",
       "      <td>17</td>\n",
       "      <td>U</td>\n",
       "      <td>GT3</td>\n",
       "      <td>T</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>at_home</td>\n",
       "      <td>other</td>\n",
       "      <td>...</td>\n",
       "      <td>5</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>9</td>\n",
       "      <td>11</td>\n",
       "      <td>11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>GP</td>\n",
       "      <td>F</td>\n",
       "      <td>15</td>\n",
       "      <td>U</td>\n",
       "      <td>LE3</td>\n",
       "      <td>T</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>at_home</td>\n",
       "      <td>other</td>\n",
       "      <td>...</td>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>6</td>\n",
       "      <td>12</td>\n",
       "      <td>13</td>\n",
       "      <td>12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>GP</td>\n",
       "      <td>F</td>\n",
       "      <td>15</td>\n",
       "      <td>U</td>\n",
       "      <td>GT3</td>\n",
       "      <td>T</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>health</td>\n",
       "      <td>services</td>\n",
       "      <td>...</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>14</td>\n",
       "      <td>14</td>\n",
       "      <td>14</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>GP</td>\n",
       "      <td>F</td>\n",
       "      <td>16</td>\n",
       "      <td>U</td>\n",
       "      <td>GT3</td>\n",
       "      <td>T</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>other</td>\n",
       "      <td>other</td>\n",
       "      <td>...</td>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>11</td>\n",
       "      <td>13</td>\n",
       "      <td>13</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 33 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "  school sex  age address famsize Pstatus  Medu  Fedu     Mjob      Fjob  ...  \\\n",
       "0     GP   F   18       U     GT3       A     4     4  at_home   teacher  ...   \n",
       "1     GP   F   17       U     GT3       T     1     1  at_home     other  ...   \n",
       "2     GP   F   15       U     LE3       T     1     1  at_home     other  ...   \n",
       "3     GP   F   15       U     GT3       T     4     2   health  services  ...   \n",
       "4     GP   F   16       U     GT3       T     3     3    other     other  ...   \n",
       "\n",
       "  famrel freetime  goout  Dalc  Walc health absences  G1  G2  G3  \n",
       "0      4        3      4     1     1      3        4   0  11  11  \n",
       "1      5        3      3     1     1      3        2   9  11  11  \n",
       "2      4        3      2     2     3      3        6  12  13  12  \n",
       "3      3        2      2     1     1      5        0  14  14  14  \n",
       "4      4        3      2     1     2      5        0  11  13  13  \n",
       "\n",
       "[5 rows x 33 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv(\"student-por.csv\", sep=\";\")\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dcb230c7-c282-4d65-bb47-c152e4fc5fdd",
   "metadata": {},
   "source": [
    "## 3. Inspect Data Structure and Missing Values\r\n",
    "We confirmed the data types of all columns and verified whether any feature contains missing values.  \r\n",
    "In this dataset, most columns are complete, but we still keep imputation in the pipeline for robustness.\r\n",
    "ed.y."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "ca62413b-1a49-4cfd-991a-689a2adaba4b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 649 entries, 0 to 648\n",
      "Data columns (total 33 columns):\n",
      " #   Column      Non-Null Count  Dtype \n",
      "---  ------      --------------  ----- \n",
      " 0   school      649 non-null    object\n",
      " 1   sex         649 non-null    object\n",
      " 2   age         649 non-null    int64 \n",
      " 3   address     649 non-null    object\n",
      " 4   famsize     649 non-null    object\n",
      " 5   Pstatus     649 non-null    object\n",
      " 6   Medu        649 non-null    int64 \n",
      " 7   Fedu        649 non-null    int64 \n",
      " 8   Mjob        649 non-null    object\n",
      " 9   Fjob        649 non-null    object\n",
      " 10  reason      649 non-null    object\n",
      " 11  guardian    649 non-null    object\n",
      " 12  traveltime  649 non-null    int64 \n",
      " 13  studytime   649 non-null    int64 \n",
      " 14  failures    649 non-null    int64 \n",
      " 15  schoolsup   649 non-null    object\n",
      " 16  famsup      649 non-null    object\n",
      " 17  paid        649 non-null    object\n",
      " 18  activities  649 non-null    object\n",
      " 19  nursery     649 non-null    object\n",
      " 20  higher      649 non-null    object\n",
      " 21  internet    649 non-null    object\n",
      " 22  romantic    649 non-null    object\n",
      " 23  famrel      649 non-null    int64 \n",
      " 24  freetime    649 non-null    int64 \n",
      " 25  goout       649 non-null    int64 \n",
      " 26  Dalc        649 non-null    int64 \n",
      " 27  Walc        649 non-null    int64 \n",
      " 28  health      649 non-null    int64 \n",
      " 29  absences    649 non-null    int64 \n",
      " 30  G1          649 non-null    int64 \n",
      " 31  G2          649 non-null    int64 \n",
      " 32  G3          649 non-null    int64 \n",
      "dtypes: int64(16), object(17)\n",
      "memory usage: 167.4+ KB\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "school        0\n",
       "sex           0\n",
       "age           0\n",
       "address       0\n",
       "famsize       0\n",
       "Pstatus       0\n",
       "Medu          0\n",
       "Fedu          0\n",
       "Mjob          0\n",
       "Fjob          0\n",
       "reason        0\n",
       "guardian      0\n",
       "traveltime    0\n",
       "studytime     0\n",
       "failures      0\n",
       "schoolsup     0\n",
       "famsup        0\n",
       "paid          0\n",
       "activities    0\n",
       "nursery       0\n",
       "higher        0\n",
       "internet      0\n",
       "romantic      0\n",
       "famrel        0\n",
       "freetime      0\n",
       "goout         0\n",
       "Dalc          0\n",
       "Walc          0\n",
       "health        0\n",
       "absences      0\n",
       "G1            0\n",
       "G2            0\n",
       "G3            0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Check basic info\n",
    "df.info()\n",
    "\n",
    "# Check missing values\n",
    "df.isna().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d684f1b6-d5d9-4ec7-af54-901d827037c1",
   "metadata": {},
   "source": [
    "## 4. Basic Feature Engineering\r\n",
    "\r\n",
    "We create a few new features that may improve model performance and interpretability:\r\n",
    "- `study_absence_interaction`: combines study time and absences  \r\n",
    "- `age_group`: bins age into categories (young, middle, older)  \r\n",
    "- `log_absences`: log-transformed absences to reduce skewness"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "a0177cde-a941-4666-beab-9e8bb4e8ad8e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>studytime</th>\n",
       "      <th>absences</th>\n",
       "      <th>study_absence_interaction</th>\n",
       "      <th>age</th>\n",
       "      <th>age_group</th>\n",
       "      <th>log_absences</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2</td>\n",
       "      <td>4</td>\n",
       "      <td>8</td>\n",
       "      <td>18</td>\n",
       "      <td>middle</td>\n",
       "      <td>1.609438</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>4</td>\n",
       "      <td>17</td>\n",
       "      <td>young</td>\n",
       "      <td>1.098612</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>6</td>\n",
       "      <td>12</td>\n",
       "      <td>15</td>\n",
       "      <td>young</td>\n",
       "      <td>1.945910</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>15</td>\n",
       "      <td>young</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>16</td>\n",
       "      <td>young</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   studytime  absences  study_absence_interaction  age age_group  log_absences\n",
       "0          2         4                          8   18    middle      1.609438\n",
       "1          2         2                          4   17     young      1.098612\n",
       "2          2         6                         12   15     young      1.945910\n",
       "3          3         0                          0   15     young      0.000000\n",
       "4          2         0                          0   16     young      0.000000"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Interaction term: studytime × absences\n",
    "df[\"study_absence_interaction\"] = df[\"studytime\"] * df[\"absences\"]\n",
    "\n",
    "# Age groups using bins\n",
    "df[\"age_group\"] = pd.cut(\n",
    "    df[\"age\"],\n",
    "    bins=[15, 17, 19, 22],\n",
    "    labels=[\"young\", \"middle\", \"older\"],\n",
    "    include_lowest=True\n",
    ")\n",
    "\n",
    "# Log-transform absences (add 1 to avoid log(0))\n",
    "df[\"log_absences\"] = np.log1p(df[\"absences\"])\n",
    "\n",
    "df[[\"studytime\", \"absences\", \"study_absence_interaction\", \"age\", \"age_group\", \"log_absences\"]].head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c04eada6-a747-4af5-841a-e91089088be1",
   "metadata": {},
   "source": [
    "We engineered new features that may capture more nuanced relationships between behavior (study time, absences, age) and performance, which can later be analyzed and modeled."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b539139a-249c-4839-998f-2a75b80b98e7",
   "metadata": {},
   "source": [
    "## 5. Split Features (X) and Target (y)\r\n",
    "\r\n",
    "We separate the input features (`X`) from the target variable (`y`).  \r\n",
    "Here, `G3` (final grade) is the prediction target, and all other columns are used as features.s.."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "a63ecaa8-af37-40a7-80c7-c3d64a6bc5ec",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X shape: (649, 35)\n",
      "y shape: (649,)\n"
     ]
    }
   ],
   "source": [
    "# Target variable\n",
    "y = df[\"G3\"]\n",
    "\n",
    "# Features: drop G3 from the dataset\n",
    "X = df.drop(\"G3\", axis=1)\n",
    "\n",
    "print(\"X shape:\", X.shape)\n",
    "print(\"y shape:\", y.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c0472ade-abc0-4905-b531-2ba2bd56968e",
   "metadata": {},
   "source": [
    " **Step 5 completed:**  \r\n",
    "We defined `y` as the final grade (G3) and `X` as all remaining columns, ensuring that the target is not used as an input feature."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "48d4c52c-ef27-401f-9290-5defd6907c66",
   "metadata": {},
   "source": [
    "## 6. Identify Numerical and Categorical Columns\r\n",
    "\r\n",
    "We automatically detect numerical and categorical columns from `X`.  \r\n",
    "This allows us to apply different preprocessing steps to each type (e.g., scaling for numeric, encoding for categorical).y.y."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "cb924533-d6f5-4de9-a53f-e0267a15d43e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Numeric columns: Index(['age', 'Medu', 'Fedu', 'traveltime', 'studytime', 'failures', 'famrel',\n",
      "       'freetime', 'goout', 'Dalc', 'Walc', 'health', 'absences', 'G1', 'G2',\n",
      "       'study_absence_interaction', 'log_absences'],\n",
      "      dtype='object')\n",
      "Categorical columns: Index(['school', 'sex', 'address', 'famsize', 'Pstatus', 'Mjob', 'Fjob',\n",
      "       'reason', 'guardian', 'schoolsup', 'famsup', 'paid', 'activities',\n",
      "       'nursery', 'higher', 'internet', 'romantic'],\n",
      "      dtype='object')\n"
     ]
    }
   ],
   "source": [
    "num_cols = X.select_dtypes(include=['int64', 'float64']).columns\n",
    "cat_cols = X.select_dtypes(include=['object']).columns\n",
    "\n",
    "print(\"Numeric columns:\", num_cols)\n",
    "print(\"Categorical columns:\", cat_cols)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "351220aa-fbcc-499f-a010-3e9455313f2b",
   "metadata": {},
   "source": [
    "**Step 6 completed:**  \r\n",
    "We identified numeric features (e.g., age, grades, absences) and categorical features (e.g., gender, address, parental jobs), which will be handled differently in the preprocessing pipeline."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bc801eac-23b3-4905-aa1c-271ba406207a",
   "metadata": {},
   "source": [
    "## 7. Build the Preprocessing Pipeline\r\n",
    "\r\n",
    "We create a `ColumnTransformer` that:\r\n",
    "- Imputes missing numeric values and scales them using `StandardScaler`\r\n",
    "- Imputes missing categorical values and encodes them using `OneHotEncoder`\r\n",
    "\r\n",
    "This ensures consistent preprocessing across all features.sing."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "7a92a405-be81-41fc-a17d-620ca2ce73cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "preprocessor = ColumnTransformer(\n",
    "    transformers=[\n",
    "        (\"num\", Pipeline(steps=[\n",
    "            (\"imputer\", SimpleImputer(strategy=\"median\")),\n",
    "            (\"scaler\", StandardScaler())\n",
    "        ]), num_cols),\n",
    "\n",
    "        (\"cat\", Pipeline(steps=[\n",
    "            (\"imputer\", SimpleImputer(strategy=\"most_frequent\")),\n",
    "            (\"encoder\", OneHotEncoder(handle_unknown=\"ignore\"))\n",
    "        ]), cat_cols)\n",
    "    ]\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b0327790-30aa-414a-b821-ad7e99cd084c",
   "metadata": {},
   "source": [
    "**Step 7 completed:**  \r\n",
    "We defined a preprocessing pipeline that standardizes numerical features and one-hot encodes categorical features, while safely handling any missing values."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "82ac61bb-33ae-42ee-84e7-c55c3bf30fd9",
   "metadata": {},
   "source": [
    "## 8. Fit and Transform Features (Create `X_processed`)\r\n",
    "\r\n",
    "We now apply the preprocessing pipeline to `X` to create a fully transformed feature matrix, ready for model training in Week 4.."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "0665cba9-7b32-47bd-a095-fc943fbaf484",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_processed created. Shape: (649, 60)\n"
     ]
    }
   ],
   "source": [
    "X_processed = preprocessor.fit_transform(X)\n",
    "print(\"X_processed created. Shape:\", X_processed.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "abd53676-d12f-470a-8c9a-68cae191b960",
   "metadata": {},
   "source": [
    "**Step 8 completed:**  \r\n",
    "We successfully transformed all features into a numerical matrix `X_processed`, combining scaled numeric features and one-hot encoded categorical features."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "725bc590-de8d-486d-b883-d27984b34801",
   "metadata": {},
   "source": [
    "## 9. Save the Processed Dataset\r\n",
    "\r\n",
    "We convert the processed feature matrix into a DataFrame, attach the target variable `G3`, and save the result as `processed_student_data.csv` for Week 4 modeling..\r\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "508eeba3-3855-4ac3-92e6-72cf3c2645cc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved processed_student_data.csv with shape: (649, 61)\n"
     ]
    }
   ],
   "source": [
    "# Convert X_processed to a dense array if it is sparse\n",
    "if hasattr(X_processed, \"toarray\"):\n",
    "    X_array = X_processed.toarray()\n",
    "else:\n",
    "    X_array = X_processed\n",
    "\n",
    "# Build processed DataFrame\n",
    "processed_df = pd.DataFrame(X_array)\n",
    "processed_df[\"G3\"] = y.values\n",
    "\n",
    "# Save to CSV\n",
    "processed_df.to_csv(\"processed_student_data.csv\", index=False)\n",
    "\n",
    "print(\"Saved processed_student_data.csv with shape:\", processed_df.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0f5d9060-6cb0-4c7e-889e-ad8441acc0ff",
   "metadata": {},
   "source": [
    "**Step 9 completed:**  \r\n",
    "We created `processed_student_data.csv`, which contains fully preprocessed features and the target grade G3.  \r\n",
    "This file will be used in **Week 4** for model training (e.g., Linear Regression, Random Forest, SVM)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "abfe2f2f-35c4-4d7c-9506-a42b9d7cf18c",
   "metadata": {},
   "source": [
    "Note: SMOTE will be applied later if we convert G3 into a classification label (e.g., pass/fail). For now, we skip balancing for the regression setup."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ce294cac-0458-4c19-ac22-9806528590f3",
   "metadata": {},
   "source": [
    "## 10. Note on Class Balancing (SMOTE for Future Work)\r\n",
    "\r\n",
    "In this notebook, `G3` is treated as a continuous regression target (0–20).  \r\n",
    "Balancing methods like **SMOTE** are mainly designed for classification problems (e.g., Pass/Fai\n",
    "\n",
    "\r\n",
    "➡️ In a future step, if we convert `G3` into a binary label such as:\r\n",
    "- Pass (G3 ≥ threshold)\r\n",
    "- Fail (G3 < threshold)\r\n",
    "\r\n",
    "then we can apply SMOTE on the classification labels to handle class imbalance fairly across groups."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "96c0a49a-3508-4dee-ac07-9dc04cd1eae5",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
